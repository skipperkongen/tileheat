% !TEX root = ./tileheat.tex
\section{Related work}
\label{sec:related}

Caching of dynamic web content has been extensively studied in a number of contexts~\cite{DDT+01:DynamicContentAcceleration,GMA+08:Ferdinand,GLR05:GoodEnough,LGZ04:MTCache,LKM+02:DBCache,Moh01:WebCaching}. A major issue investigated by these proposals is the policy used to keep the cache up-to-date. 
For example, Guo et al.~\cite{GLR05:GoodEnough} propose a set of declarative constraints that specify presence,  consistency, completeness, and currency of cached content. 
Garrod et al.~\cite{GMA+08:Ferdinand} explore how to take advantage of multiple cache servers while maintaining consistency. In contrast, our workload analysis shows that the main challenge for a geographical web service is the computational expense of the refresh procedure of the tile cache, rather than the freshness of relatively slowly updated map data. In this sense, our approach can be seen as similar to periodically refreshing a materialized view. This  ``view'' delivers the tile pyramid based on the underlying geographical data; however, it is both spatial and includes external user-defined functions to compute tile content. While similar in spirit to the materialized-view approach of MTCache~\cite{LGZ04:MTCache}, the additional complexities of our domain render the problem harder in several ways: First, not all of the view definition is available to the system, making it more difficult to predict which tiles are affected by which data and recompute selectively. Second, only portions of the view are of interest to end users, due to skew in access patterns, and it is not obvious how to define which portions are interesting ahead of time. Third, computation of tiles is a very resource-intensive user-defined function, making even a partial refresh of the spatial cache costly.  
 
Our work can also be seen as a self-tuning approach to managing a tile web cache~\cite{CN07:SelfTuning10YrPaper}. Similarly to online self-tuning approaches, such as COLT~\cite{SAMP07:COLT} and the seminal COMFORT~\cite{WHMZ94:COMFORT} project, TileHeat operates on a feedback loop, collecting workload characteristics, performing reasoning for choosing a new system configuration, and introducing configuration changes as necessary. However, our work differs in both the characterization of the problem as well as in the design choices we make for each step of our feedback loop. 
In particular, our choices are motivated by a careful analysis of the production log of a country-wide geographical web service. 
%We derive several conclusions from the analysis: 1) The access patterns of the rendering service exhibit high regularity, with low activity off day hours; 2) Access patterns can be largely inferred based on historical data, 3) The cost for materialization of tiles for caching is significant, and consequently services with moderate update rates -- such as geographical web services -- can dramatically profit from a selective cache.  

Adaptive algorithms have been studied for the classic buffer cache replacement problem, including 2Q~\cite{JS94:2Q}, ARC~\cite{MM03:ARC}, and LRU-K~\cite{OOW93:LRU-K}. Our work, however, is focused on the different scenario of spatial web caching, in which tiles are materialized in advance of processing the workload.
% Unlike previous caching algorithms, our approach takes advantage of the capability to observe the workload for a given time period, and uses the collected data to materialize a spatial cache for the next period.  
As in semantic caching~\cite{DFJ+96:SemanticCaching}, we exploit application characteristics to decide what data to cache and update. In contrast to semantic caching, we exploit spatial properties for higher web cache hit ratios, such as with our heat dissipation method. 
	
The basic idea of using heat to measure popularity of data items arises naturally in applications with skewed access patterns. For example, Scheuermann et al.~\cite{SWZ93:DiskCooling} propose schemes for data placement and adaptive load balancing that "cool" disks by redistributing file fragments. In spatial services more specifically, many researchers have observed that there is a strong skew in the access frequencies of tiles, and that this skew follows a power law~\cite{fisher07,LGXF12:SpatialPrefetching,talagala00}. Li et al.~\cite{LGXF12:SpatialPrefetching} exploit skew to create a pre-fetching model of spatial tiles, with focus on predicting short-term user navigation. Their work is based on a substantial body of related short-term prediction approaches~\cite{KKK01:Prefetching,KKK01:Prefetching2,LKK+02:Prefetching}. These methods are optimized for pre-fetching  tiles seconds before they are requested by a user. The amount of pre-fetching done during a time period is thus proportional to the load. As we have observed, load and latency are proportional, which means that pre-fetching in real time does little to alleviate load peaks. To reduce the high latency caused by load peaks, we instead pre-compute tiles during periods of low load. To achieve this, we develop methods that do not rely on the input of individual users browsing a map in real time. 
%In contrast, we look at the problem of pre-computing a large set of tiles that comprise a production-grade spatial web cache. 

As discussed in Section~\ref{sec:existing:methods}, Quinn and Gahegan~\cite{quinn10} suggest using certain classes of base objects, such as roads and coastlines, as predictors of where users will look at a map. However, as observed in Fisher's study of Microsoft Hotmap~\cite{fisher07}, real-world workloads can contradict models of rational user behavior, exclusively focused on a fixed set of rules. An example given by Fisher~\cite{fisher07} was a banner ad that caused frequent requests for ``empty'' parts of the Pacific Ocean. Based on such observations of real-life events, Fisher develops a multi-scale descriptive model that quantifies web map usage based on a heatmap. Their study supports our observation that anomalous patterns may be transient in time, but partially detectable from a training data set. In contrast to Fisher, however, we exploit this insight to propose multiple strategies to keep hit ratios on a spatial web cache high, while at the same time drastically reducing resource consumption during recomputation of tiles. 

